from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from lightrag import QueryParam
from models.deepseek_lightrag import get_rag_instance
from services.session_store import user_sessions, user_exists, get_user_name
from services.keyword_extractor import extract_keywords_from_gpt
from services.utils import parse_json_from_response
import asyncio
from services.user_type_extractor import save_user_type_async
import json

router = APIRouter()

class ChatRequest(BaseModel):
    userMessage: str
    userId: str

class ChatResponse(BaseModel):
    responseText: str
    canRecommend: bool

@router.post("/chat", response_model=ChatResponse)
async def chat_handler(req: ChatRequest):
    rag = await get_rag_instance()
    user_id = req.userId
    user_message = req.userMessage

    if not user_exists(user_id):
        raise HTTPException(status_code=401, detail="ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ìš©ìì…ë‹ˆë‹¤. ë¨¼ì € /usersì—ì„œ ë“±ë¡í•´ ì£¼ì„¸ìš”.")

    session = user_sessions[user_id]
    session["messages"].append({"role": "user", "content": user_message})
    user_name = get_user_name(user_id)

    keywords = await extract_keywords_from_gpt(user_message)
    session["keywords"].extend(kw for kw in keywords if kw not in session["keywords"])

    if len(session["keywords"]) >= 3:
        session["can_recommend"] = True

        recommend_system_prompt = """
        ë„ˆëŠ” ì±… ì¶”ì²œ ì‹œìŠ¤í…œì´ì•¼. ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ì—ì„œ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì±… ì œëª©ì„ ë¬´ì¡°ê±´ 3ê°œ JSONìœ¼ë¡œ ë°˜í™˜í•´.
        titleì— í•´ë‹¹í•˜ëŠ” ì œëª©ë§Œ ë§í•´ì¤˜.
        í˜•ì‹: {{ "titles": ["ì¶”ì²œ ì±… ì œëª©1", "ì¶”ì²œ ì±… ì œëª©2", "ì¶”ì²œ ì±… ì œëª©3"] }} ì™¸ í…ìŠ¤íŠ¸ ê¸ˆì§€
        """
        query = "ì‚¬ìš©ìì™€ì˜ ëŒ€í™”:\n" + "\n".join(f"{m['role']}: {m['content']}" for m in session["messages"])
        response = await rag.aquery(
            query,
            param=QueryParam(mode="local", conversation_history=session["messages"], history_turns=5),
            system_prompt=recommend_system_prompt
        )

        with open("books_with_age.json", "r", encoding="utf-8") as f:
            book_data = json.load(f)
        db_titles = set(book["title"] for book in book_data)

        book_titles = parse_json_from_response(response, key="titles") or []
        # âœ… ë¶€ë¶„ ì¼ì¹˜ë¡œ í•„í„°ë§
        filtered_titles = [
            candidate for candidate in book_titles
            if any(candidate in db_title for db_title in db_titles)
        ]

        if filtered_titles:
            session["recommended_titles"] = filtered_titles[:3]
            asyncio.create_task(save_user_type_async(user_id, session["messages"]))
            title_preview = "', '".join(session["recommended_titles"])
            responseText = f"{user_name}ë‹˜ê»˜ ì¶”ì²œë“œë¦´ ì±…ì´ ìˆì–´ìš”! ğŸ“š '{title_preview}' ì„(ë¥¼) ê³§ ì•Œë ¤ë“œë¦´ê²Œìš”."
            session["messages"].append({"role": "assistant", "content": responseText})
            return {"responseText": responseText, "canRecommend": True}
        else:
            session["can_recommend"] = False
            session["recommended_titles"] = []

    # ì¶”ê°€ ì •ë³´ ìœ ë„ ì§ˆë¬¸
    interview_prompt = f"""
    ë„ˆëŠ” ì±… MBTI í…ŒìŠ¤íŠ¸ì˜ ì¸í„°ë·°ì–´ì•¼. ì‚¬ìš©ì({user_name}ë‹˜)ì˜ ì„±ê²©ê³¼ ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ íŒŒì•…í•´ì„œ ì±…ì„ ì¶”ì²œí•˜ê¸° ìœ„í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´.
    ì§ˆë¬¸ì€ ëŒ€í™”ì²´ë¡œ ì§§ê²Œ ë§í•´ì¤˜. ì˜ˆ: 'ì£¼ë§ì—” í˜¼ì ì‰¬ëŠ” ê±¸ ì¢‹ì•„í•˜ì„¸ìš”, ì¹œêµ¬ë“¤ê³¼ ì–´ìš¸ë¦¬ëŠ” ê±¸ ì¢‹ì•„í•˜ì„¸ìš”?', 'í•™êµì— ë‹¤ë‹ˆì‹œë‚˜ìš”?'
    """
    context = "ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©ì ëŒ€í™”: " + " ".join(m["content"] for m in session["messages"])
    followup = await rag.aquery(
        context,
        param=QueryParam(mode="global", conversation_history=session["messages"], history_turns=5),
        system_prompt=interview_prompt
    )

    session["messages"].append({"role": "assistant", "content": followup})
    return {"responseText": followup, "canRecommend": False}
